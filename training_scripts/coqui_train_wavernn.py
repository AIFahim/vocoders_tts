# -*- coding: utf-8 -*-
"""coqui_train_mbmelgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z7MqZdP0TdLXPFgTOqtf3afwTIXIGGOF
"""

#vocoder


import os

from trainer import Trainer, TrainerArgs

from TTS.utils.audio import AudioProcessor
from TTS.vocoder.configs import WavernnConfig
from TTS.vocoder.datasets.preprocess import load_wav_data
from TTS.vocoder.models.wavernn import Wavernn
from TTS.config.shared_configs import BaseAudioConfig
from TTS.tts.configs.shared_configs import BaseDatasetConfig , CharactersConfig
from TTS.tts.datasets import load_tts_samples




output_path = os.path.dirname(os.path.abspath(__file__))
# dataset_config = BaseDatasetConfig(
#     formatter="mozilla", meta_file_train="metadata.csv", path="/kaggle/input/persian-tts-dataset-famale" 
# )
audio_config = BaseAudioConfig(
    sample_rate=16000,
    do_trim_silence=True,
    resample=True,
    mel_fmin=95,
    mel_fmax=8000.0,
)

config = WavernnConfig(
    batch_size=64,#
    eval_batch_size=16,#
    num_loader_workers=1,
    num_eval_loader_workers=1,
    run_eval=True,
    test_delay_epochs=-1,
    epochs=1000,
    seq_len=1280,
    pad_short=2000,
    use_noise_augment=False,
    save_step=1000,
    eval_split_size=10,
    print_step=25,
    print_eval=True,
    mixed_precision=False,
    lr=1e-4,
    data_path="/home/asif/dataset_tts/train_female/wavs/",
    output_path=output_path,
    audio=audio_config,
    
)

# init audio processor
ap = AudioProcessor(**config.audio.to_dict())

# load training samples
eval_samples, train_samples = load_wav_data(config.data_path, config.eval_split_size)

# init model
model = Wavernn(config)

# init the trainer and üöÄ
trainer = Trainer(
    TrainerArgs(),
    config,
    output_path,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
    training_assets={"audio_processor": ap},
)
trainer.fit()






"""
import os

from trainer import Trainer, TrainerArgs

from TTS.utils.audio import AudioProcessor
from TTS.vocoder.configs import MultibandMelganConfig
from TTS.vocoder.datasets.preprocess import load_wav_data
from TTS.vocoder.models.gan import GAN

output_path = os.path.dirname(os.path.abspath(__file__))

# config = MultibandMelganConfig(
#     batch_size=32,
#     eval_batch_size=16,
#     num_loader_workers=4,
#     num_eval_loader_workers=4,
#     run_eval=True,
#     test_delay_epochs=5,
#     epochs=1000,
#     seq_len=8192,
#     pad_short=2000,
#     use_noise_augment=True,
#     eval_split_size=10,
#     print_step=25,
#     print_eval=False,
#     mixed_precision=False,
#     lr_gen=1e-4,
#     lr_disc=1e-4,
#     data_path="/home/asif/dataset_tts/train_female/wavs/", #os.path.join(output_path, "../LJSpeech-1.1/wavs/"),
#     output_path=output_path,
# )

# # init audio processor
# ap = AudioProcessor(**config.audio.to_dict())

# # load training samples
# eval_samples, train_samples = load_wav_data(config.data_path, config.eval_split_size)


config = MultibandMelganConfig(
    batch_size=256,
    eval_batch_size=16,
    num_loader_workers=4,
    num_eval_loader_workers=4,
    run_eval=True,
    test_delay_epochs=5,
    epochs=1000,
    seq_len=8192,
    pad_short=2000,
    use_noise_augment=True,
    eval_split_size=10,
    print_step=25,
    print_eval=False,
    mixed_precision=False,
    lr_gen=1e-4,
    lr_disc=1e-4,
    data_path="",
    output_path=output_path,
    steps_to_start_discriminator=0
)


# init audio processor
ap = AudioProcessor(**config.audio.to_dict())

# load training samples
eval_samples, train_samples=[[],[]]
for path in ["/home/asif/dataset_tts/train_female/wavs"]: 
    eval_samples_temp, train_samples_temp = load_wav_data(path, config.eval_split_size)
    eval_samples+=eval_samples_temp
    train_samples+=train_samples_temp
    
# print(train_samples_temp)

# assert False

# # init model
# model = GAN(config, ap)

# # init the trainer and üöÄ
# trainer = Trainer(
#     TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples
# )
# trainer.fit()

# init model
model = GAN(config)

# init the trainer and üöÄ
trainer = Trainer(
    TrainerArgs(),
    
    config,
    output_path,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
    training_assets={"audio_processor": ap},
)
trainer.fit()

"""














'''
import os
# import TTS
# from TTS.trainer import Trainer, TrainingArgs
from TTS.utils.audio import AudioProcessor
from TTS.vocoder.configs import HifiganConfig, MultibandMelganConfig
from TTS.vocoder.datasets.preprocess import load_wav_data
from TTS.vocoder.models.gan import GAN

from TTS.tts.configs.shared_configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig
from TTS.tts.configs.glow_tts_config import GlowTTSConfig
from TTS.tts.configs.align_tts_config import AlignTTSConfig
from TTS.utils.audio import AudioProcessor
from TTS.tts.utils.text.tokenizer import TTSTokenizer
from TTS.tts.models.glow_tts import GlowTTS
from TTS.tts.models.align_tts import AlignTTS
from TTS.tts.datasets import load_tts_samples
from trainer import Trainer, TrainerArgs

from TTS.vocoder.models.gan import GAN

# assert False 

output_path =os.path.join("./model/vocoder/mbmelgan/")
# output_path = "checkpoints_bn_female_new"

dataset_config = BaseDatasetConfig(
    formatter="ljspeech", meta_file_train="/home/asif/dataset_tts/train_female/metadata.txt", path="/home/asif/dataset_tts/train_female" # os.path.join(output_path, "LJSpeech-1.1/"
)

# GlowTTSConfig: all model related values for training, validating and testing.
my_valid_lis= ["-", "‡¶Ö", "‡¶Ü", "‡¶á", "‡¶à", "‡¶â", "‡¶ä", "‡¶ã", "‡¶è", "‡¶ê", "‡¶ì", "‡¶î", "‡¶ï", "‡¶ñ", "‡¶ó", "‡¶ò", "‡¶ô", "‡¶ö", 
        "‡¶õ", "‡¶ù", "‡¶ú", "‡¶ü", "‡¶†", "‡¶°", "‡¶¢", "‡¶£", "‡¶§", "‡¶•", "‡¶¶", "‡¶ß", "‡¶®", "‡¶™", "‡¶´", "‡¶¨", "‡¶≠", "‡¶Æ", "‡¶Ø", 
        "‡ßü", "‡¶∞", "‡¶≤", "‡¶¨", "‡¶∂", "‡¶∑", "‡¶∏", "‡¶π", "‡¶û", "‡¶°‡¶º", "‡¶¢‡¶º", "‡ßé", "‡¶ø", "‡¶æ", "‡ßÇ", "‡ßÅ", "‡ßÉ", "‡ßà", "‡¶É", 
        "‡ßã", "‡ßå", ",", ";", ":", "?", "!", "‡•§", "‚Äî", "‚Ä¶", "#", "‡ßß", "‡ß®", "‡ß©", "‡ß™", "‡ß´", "‡ß¨", "‡ß≠", "‡ßÆ", "‡ßØ", 
        "‡ß¶", "‡ßç", "\u200c", "‡ßá", " ", "‡ßç", "‡¶º", "‡¶Å", "‡ßÄ", "‡¶Ç", "‡ßú", ".", "\u200d", "‡ßù", "‚Äô", "‚Äò", "‚Äô", "‡ß∑", 
        "‚Äú", "‚Äù", "'", "\\", "(", ")", "\u200b", "3", "\xad", "‡ßó", "\"", "¬Ø", "\xad", "\xad", "\u206e", "\xad"]
# print(str(my_valid_lis))
# assert False
# char_list = ['a', 'a_1', 'a_2', 'aÃÉ', 'aÃÉ_1', 'aÃÉ_2', 'b', 'b_1', 'b_2', 'b ∞', 'b ∞_1', 'b ∞_2', 'c', 'c_1', 'c_2', 'c ∞', 'c ∞_1', 'c ∞_2', 'd', 'd_1', 'd_2', 'd ∞', 'd ∞_1', 'd ∞_2', 'dÃ™', 'dÃ™_1', 'dÃ™_2', 'dÃ™ ∞', 'dÃ™ ∞_1', 'dÃ™ ∞_2', 'e', 'e_1', 'e_2', 'eÃÉ', 'eÃÉ_1', 'eÃÉ_2', 'g', 'g_1', 'g_2', 'g ∞', 'g ∞_1', 'g ∞_2', 'h', 'h_1', 'h_2', 'i', 'i_1', 'i_2', 'iÃÉ', 'iÃÉ_1', 'iÃÉ_2', 'iÃØ', 'iÃØ_2', 'k', 'k_1', 'k_2', 'k ∞', 'k ∞_1', 'k ∞_2', 'l', 'l_1', 'l_2', 'm', 'm_1', 'm_2', 'n', 'n_1', 'n_2', 'o', 'o_1', 'o_2', 'oÃÉ', 'oÃÉ_1', 'oÃÉ_2', 'oÃØ', 'oÃØ_1', 'oÃØ_2', 'p', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p_1', 'p_2', 'p ∞', 'p ∞_1', 'p ∞_2', 'r', 'r_1', 'r_2', 's', 's_1', 's_2', 't', 't_1', 't_2', 't ∞', 't ∞_1', 't ∞_2', 'tÃ™', 'tÃ™_1', 'tÃ™_2', 'tÃ™ ∞', 'tÃ™ ∞_1', 'tÃ™ ∞_2', 'u', 'u_1', 'u_2', 'uÃÉ', 'uÃÉ_1', 'uÃÉ_2', 'uÃØ', 'uÃØ_2', '√¶', '√¶_1', '√¶_2', '√¶ÃÉ', '√¶ÃÉ_2', '≈ã', '≈ã_2', '…î', '…î_1', '…î_2', '…îÃÉ', '…îÃÉ_2', '…ü', '…ü_1', '…ü_2', '…ü ∞', '…ü ∞_1', '…ü ∞_2', '…Ω', '…Ω_2', '…Ω ∞', ' É', ' É_1', ' É_2', ' ≤', ' ≤_2', ' ∑']

# traverse in the string
# char_sen = ""
# for x in my_valid_lis:
#     char_sen += x
# # print(char_sen)
characters_config = CharactersConfig(
    pad = '',#'<PAD>',
    eos = '',#'\n', #'<EOS>', #'‡•§',
    bos = '',#'<BOS>',# None,
    blank = '',#'<BLNK>',
    phonemes = None,
    # characters =  "‡¶§‡¶ü‡ß´‡¶≠‡¶ø‡¶ê‡¶ã‡¶ñ‡¶ä‡ßú‡¶á‡¶ú‡¶Æ‡¶è‡ßá‡¶ò‡¶ô‡¶∏‡ßÄ‡ßù‡¶π‡¶û‚Äò‡¶à‡¶ï‡¶£‡ß¨‡¶Å‡ßó‡¶∂‡¶¢‡¶†\u200c‡ßß‡ßç‡ß®‡ßÆ‡¶¶‡ßÉ‡¶î‡¶ó‡¶ì‚Äî‡¶õ‡¶â‡¶Ç‡¶¨‡ßà‡¶ù‡¶æ‡¶Ø‡¶´\u200d‡¶ö‡¶∞‡¶∑‡¶Ö‡ßå‡ßé‡¶•‡¶°‡¶º‡ß™‡¶ß‡ß¶‡ßÅ‡ßÇ‡ß©‡¶Ü‡¶É‡¶™‡ßü‚Äô‡¶®‡¶≤‡ßã",


    characters = my_valid_lis ,#char_sen,
    punctuations = '' # "-!,|.? ",
)


audio_config = BaseAudioConfig(
    sample_rate = 16000,
    resample =True
)
config = MultibandMelganConfig(
    # batch_size=256,
    # eval_batch_size=16,
    # num_loader_workers=4,
    # num_eval_loader_workers=4,
    # run_eval=True,
    # test_delay_epochs=5,
    # text_cleaner="collapse_whitespace",
    # epochs=1000,
    # seq_len=8192,
    # pad_short=2000,
    # use_noise_augment=True,
    # eval_split_size=10,
    # print_step=25,
    # print_eval=False,
    # mixed_precision=False,
    # lr_gen=1e-4,
    # lr_disc=1e-4,
    # data_path="",
    # output_path=output_path,
    # steps_to_start_discriminator=0

    batch_size=16,
    eval_batch_size=8,
    num_loader_workers=4,
    num_eval_loader_workers=4,
    run_eval=True,
    test_delay_epochs=-1,
    epochs=1000,
    # text_cleaner="collapse_whitespace",
    # use_phonemes=False,
    # phoneme_language="bn",
    # phoneme_cache_path=os.path.join(output_path, "phoneme_cache"),
    print_step=25,
    print_eval=True,
    mixed_precision=True,
    output_path=output_path,
    # datasets=[dataset_config],
    save_step=1000,
    audio=audio_config,
    # characters=characters_config,
    cudnn_benchmark=True,
#     test_sentences = [
#         "‡¶™‡¶ø‡¶™‡¶≤‡¶∏ ‡¶á‡¶®‡ßç‡¶∏‡ßç‡¶Ø‡ßÅ‡¶∞‡ßá‡¶®‡ßç‡¶∏ ‡¶Ö‡¶¨ ‡¶ö‡¶æ‡ßü‡¶®‡¶æ ‡¶õ‡ßá‡¶∑‡¶ü‡ßç‡¶ü‡¶ø ‡¶¨‡¶õ‡¶∞ ‡¶Ü‡¶ó‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡¶æ ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶ï‡¶∞‡ßá‡•§"
# #         "‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶≤‡¶¨‡¶æ‡¶∏‡¶ø‡•§"
#         # "‡¶π‡ßü,‡¶π‡ßü‡ßá,‡¶ì‡ßü‡¶æ,‡¶π‡ßü‡ßá‡¶õ,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶¶‡¶æ‡ßü,‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü,‡¶Ü‡ßü,‡¶≠‡ßü,‡¶®‡ßü,‡¶Ü‡ßü‡¶æ‡¶§,‡¶®‡¶ø‡ßü‡ßá,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá,‡¶∞‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá‡¶õ‡ßá‡•§",
#         # "‡¶¶‡ßá‡ßü,‡¶¶‡ßá‡¶ì‡ßü‡¶æ,‡¶¨‡¶ø‡¶∑‡ßü,‡¶π‡ßü,‡¶π‡¶ì‡ßü‡¶æ,‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡ßü,‡¶∏‡¶Æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡¶ø,‡¶π‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶¨‡¶ø‡¶∑‡ßü‡ßá,‡¶®‡ßü,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ,‡¶á‡ßü‡¶æ,‡¶¶‡ßá‡ßü‡¶æ,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá,‡¶Ü‡ßü‡¶æ‡¶§‡ßá,‡¶¶‡ßü‡¶æ‡•§",
#         # "‡¶π‡¶ì‡ßü‡¶æ‡¶∞,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü‡¶á,‡¶∞‡¶æ‡ßü,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ‡¶§,‡¶â‡¶≠‡ßü,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá‡¶®,‡¶¶‡ßÅ‡¶®‡¶ø‡ßü‡¶æ,‡¶®‡ßç‡¶Ø‡¶æ‡ßü,‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡ßü,‡¶Ø‡¶æ‡ßü,‡¶´‡¶ø‡¶∞‡¶ø‡ßü‡ßá,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶≠‡ßü‡ßá,‡¶¶‡ßç‡¶¨‡¶ø‡¶§‡ßÄ‡ßü,‡¶¶‡¶æ‡ßü‡¶ï,‡¶™‡¶æ‡ßü‡•§",
#         # "‡¶ó‡¶ø‡ßü‡ßá,‡¶ö‡ßá‡ßü‡ßá,‡¶π‡¶ø‡¶¶‡¶æ‡ßü‡¶æ‡¶§,‡¶¶‡¶æ‡ßü‡ßá,‡¶®‡¶ø‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá‡¶õ‡ßá,‡¶∂‡ßü‡¶§‡¶æ‡¶®,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ‡¶§‡ßá,‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡ßü‡ßá,‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡ßü‡ßá‡¶∞,‡¶®‡ßá‡ßü,‡¶ú‡ßü,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ‡¶§‡ßá‡¶∞,‡¶∏‡ßç‡¶•‡¶æ‡ßü‡ßÄ,‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ,‡¶¶‡ßü‡¶æ‡¶≤‡ßÅ‡•§",
#         # "‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶,‡¶®‡ßü,‡¶¨‡ßç‡¶Ø‡ßü,‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶‡ßÄ,‡¶®‡ßá‡¶ì‡ßü‡¶æ,‡¶â‡¶≠‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡•§"
#         # " É_1 …î n n o b o tÃ™ i_2 …î_1 r tÃ™ tÃ™ ∞ o_2 c ∞_1 i  ≤ a n …î b b o iÃØ_2  É_1 o ≈ã k ∞ o k_2" #‡¶∑‡¶£‡ßç‡¶®‡¶¨‡¶§‡¶ø ‡¶Ö‡¶∞‡ßç‡¶• ‡¶õ‡¶ø‡ßü‡¶æ‡¶®‡¶¨‡ßç‡¶¨‡¶á ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶ï‡•§|
#     ],
)


# init audio processor
ap = AudioProcessor(**config.audio.to_dict())
tokenizer, config = TTSTokenizer.init_from_config(config)
# load training samples
def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument
    # Normalizes the LJSpeech meta data file to TTS format
    # https://keithito.com/LJ-Speech-Dataset/
    txt_file = meta_file
    items = []
    speaker_name = "ljspeech"
    with open(txt_file, "r", encoding="utf-8") as ttf:
        for line in ttf:
            cols = line.split("|")
            wav_file = os.path.join(root_path, "wav", cols[0] + ".wav")
            try:
                text = cols[2]
            except:
                print("not found")

            items.append({"text": text, "audio_file": wav_file, "speaker_name": speaker_name, "root_path": root_path})
    return items


train_samples, eval_samples = load_tts_samples(
    dataset_config,
    eval_split=True,
    eval_split_max_size=100,#config.eval_split_max_size,
    eval_split_size=config.eval_split_size,
    formatter=formatter,
)
# eval_samples, train_samples=[[],[]]
# for path in ["/home/asif/dataset_tts/train_female/wavs"]:
#     eval_samples_temp, train_samples_temp = load_wav_data(path, config.eval_split_size)
#     eval_samples+=eval_samples_temp
#     train_samples+=train_samples_temp

# eval_samples

# init model
model = GAN(config)

print(model)

# init the trainer and üöÄ
trainer = Trainer(
    TrainerArgs(),
    config,
    output_path,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
    training_assets={"audio_processor": ap},
)
trainer.fit()

'''